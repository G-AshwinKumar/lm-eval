Tasks,Metric,medalpaca-7b [fe309fcb],openchat_3.5 [a253722a],shot_SOLAR-10.7B-Instruct-v1.0 [ea9ecbd3],shot_internlm-7b [3fc53f0d],Nous-Hermes-2-SOLAR-10.7B [74a88fe8],shot_BioMedGPT-LM-7B [011fa1d3]
mmlu,acc,0.4707 ± 0.0040,0.6353 ± 0.0038,,,,
 - humanities,acc,0.4162 ± 0.0069,0.5934 ± 0.0067,,,,
 - other,acc,0.5829 ± 0.0087,0.6965 ± 0.0079,,,,
 - social_sciences,acc,0.5382 ± 0.0087,0.7416 ± 0.0077,,,,
 - stem,acc,0.3758 ± 0.0084,0.5338 ± 0.0085,,,,
hendrycks_ethics,acc,0.6558 ± 0.0033,0.7997 ± 0.0028,0.8321 ± 0.0026,0.6088 ± 0.0034,0.8322 ± 0.0026,0.6468 ± 0.0033
crows_pairs,likelihood_diff,4.8525 ± 0.0509,4.4378 ± 0.0472,5.5089 ± 0.0565,5.4162 ± 0.0562,4.5712 ± 0.0470,4.0976 ± 0.0452
,pct_stereotype,0.6872 ± 0.0056,0.6816 ± 0.0056,0.7108 ± 0.0055,0.5929 ± 0.0059,0.7212 ± 0.0054,0.6944 ± 0.0056
 - medicine,acc,0.5717 ± 0.0367,0.6504 ± 0.0349,0.7030 ± 0.0333,0.4147 ± 0.0362,0.6767 ± 0.0343,0.4965 ± 0.0368
stem,acc,,,0.5566 ± 0.0058,0.4156 ± 0.0058,0.5568 ± 0.0058,0.4413 ± 0.0058
,acc_norm,,,0.5064 ± 0.0068,,,0.4010 ± 0.0066
